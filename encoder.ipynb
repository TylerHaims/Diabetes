{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7: Autoencoders and Generative Adversarial Neural Networks (GANs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond neural networks for classification and regression, there is a world of interesting neural network research with very cool applications. In todays lecture we have talked about *latent spaces* and their importance in \n",
    "*generative models*. Generative models are, as the name suggests, models which define a procedure for *generating* data that look similar to the trianing data. They learn the underlying structure of the data, a (lower-dimensional) structure that can be explored to obtain new datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU, Input, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input of an autoencoder is typically some multi-dimensional tensor like an image and the output is a reconstruction of said tensor/image. The loss function typically used is squared error loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.2**: What is the \"bottleneck\" of an autoencoder? How can you use the autoencoder to encode and decode data once it has been trained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"bottleneck\" of an autoencoder is the layer in the architecture with the least amount of neurons, where it's most condensed. The first half of the autoencoder encodes inputs by compressing the input it into fewer dimensions (a representation of the image in the latent space) while the second half of the autoencoder decodes the compressed input (interprests the latent space representation), restoring it as best as possible to its original form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('Diabetes2015/diabetes_binary_5050split_health_indicators_BRFSS2015.csv')\n",
    "\n",
    "X = diabetes.drop('Diabetes_binary', axis=1)\n",
    "Y = diabetes['Diabetes_binary']\n",
    "\n",
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# scale data\n",
    "t = MinMaxScaler()\n",
    "t.fit(x_train)\n",
    "x_train = t.transform(x_train)\n",
    "x_test = t.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having worked with Keras for a while now, the construction of an autoencoder is simple. Following this [tutorial](https://www.tensorflow.org/tutorials/generative/autoencoder) we construct a subclass of the `keras.models.Model` class called `Autoencoder` that inherits the some methods we want for training (`.compile`, `.fit`) and inference (`.predict`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 21\n",
    "\n",
    "# define encoder\n",
    "visible = Input(shape=(n_inputs,))\n",
    "\n",
    "# encoder level 1\n",
    "e = Dense(n_inputs*2)(visible)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# encoder level 2\n",
    "e = Dense(n_inputs)(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# encoder level 3\n",
    "e = Dense(round(float(n_inputs) / 2))(e)\n",
    "e = BatchNormalization()(e)\n",
    "e = LeakyReLU()(e)\n",
    "\n",
    "# bottleneck\n",
    "n_bottleneck = round(float(n_inputs) / 3)\n",
    "bottleneck = Dense(n_bottleneck)(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decoder, level 1\n",
    "d = Dense(round(float(n_inputs / 2)))(bottleneck)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 2\n",
    "d = Dense(n_inputs)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# decoder level 3\n",
    "d = Dense(n_inputs*2)(d)\n",
    "d = BatchNormalization()(d)\n",
    "d = LeakyReLU()(d)\n",
    "\n",
    "# output layer\n",
    "output = Dense(n_inputs, activation='linear')(d)\n",
    "\n",
    "# define autoencoder model\n",
    "model = Model(inputs=visible, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile autoencoder model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.3**: Run the code below to train the autoencoder on the mnist fashion data and visualize it attempting to encode the test data into a latent space and then decode it. How high do you have to go before you can make out the letter \"Lee\" on the jumper or the plaid/checkered pattern on the shirt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1547/1547 - 2s - 2ms/step - loss: 0.0810 - val_loss: 0.0456\n",
      "Epoch 2/40\n",
      "1547/1547 - 1s - 678us/step - loss: 0.0486 - val_loss: 0.0385\n",
      "Epoch 3/40\n",
      "1547/1547 - 1s - 683us/step - loss: 0.0433 - val_loss: 0.0337\n",
      "Epoch 4/40\n",
      "1547/1547 - 1s - 679us/step - loss: 0.0400 - val_loss: 0.0318\n",
      "Epoch 5/40\n",
      "1547/1547 - 1s - 675us/step - loss: 0.0373 - val_loss: 0.0297\n",
      "Epoch 6/40\n",
      "1547/1547 - 1s - 709us/step - loss: 0.0354 - val_loss: 0.0273\n",
      "Epoch 7/40\n",
      "1547/1547 - 1s - 678us/step - loss: 0.0335 - val_loss: 0.0258\n",
      "Epoch 8/40\n",
      "1547/1547 - 1s - 686us/step - loss: 0.0314 - val_loss: 0.0239\n",
      "Epoch 9/40\n",
      "1547/1547 - 1s - 683us/step - loss: 0.0290 - val_loss: 0.0222\n",
      "Epoch 10/40\n",
      "1547/1547 - 1s - 759us/step - loss: 0.0266 - val_loss: 0.0204\n",
      "Epoch 11/40\n",
      "1547/1547 - 1s - 722us/step - loss: 0.0247 - val_loss: 0.0190\n",
      "Epoch 12/40\n",
      "1547/1547 - 1s - 741us/step - loss: 0.0233 - val_loss: 0.0182\n",
      "Epoch 13/40\n",
      "1547/1547 - 1s - 707us/step - loss: 0.0222 - val_loss: 0.0182\n",
      "Epoch 14/40\n",
      "1547/1547 - 1s - 683us/step - loss: 0.0206 - val_loss: 0.0159\n",
      "Epoch 15/40\n",
      "1547/1547 - 1s - 676us/step - loss: 0.0196 - val_loss: 0.0151\n",
      "Epoch 16/40\n",
      "1547/1547 - 1s - 677us/step - loss: 0.0186 - val_loss: 0.0141\n",
      "Epoch 17/40\n",
      "1547/1547 - 1s - 676us/step - loss: 0.0175 - val_loss: 0.0126\n",
      "Epoch 18/40\n",
      "1547/1547 - 1s - 678us/step - loss: 0.0164 - val_loss: 0.0121\n",
      "Epoch 19/40\n",
      "1547/1547 - 1s - 676us/step - loss: 0.0158 - val_loss: 0.0127\n",
      "Epoch 20/40\n",
      "1547/1547 - 1s - 716us/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 21/40\n",
      "1547/1547 - 1s - 684us/step - loss: 0.0148 - val_loss: 0.0114\n",
      "Epoch 22/40\n",
      "1547/1547 - 1s - 687us/step - loss: 0.0144 - val_loss: 0.0107\n",
      "Epoch 23/40\n",
      "1547/1547 - 1s - 713us/step - loss: 0.0139 - val_loss: 0.0098\n",
      "Epoch 24/40\n",
      "1547/1547 - 1s - 680us/step - loss: 0.0134 - val_loss: 0.0098\n",
      "Epoch 25/40\n",
      "1547/1547 - 1s - 678us/step - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 26/40\n",
      "1547/1547 - 1s - 681us/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 27/40\n",
      "1547/1547 - 1s - 714us/step - loss: 0.0120 - val_loss: 0.0086\n",
      "Epoch 28/40\n",
      "1547/1547 - 1s - 674us/step - loss: 0.0117 - val_loss: 0.0085\n",
      "Epoch 29/40\n",
      "1547/1547 - 1s - 684us/step - loss: 0.0115 - val_loss: 0.0079\n",
      "Epoch 30/40\n",
      "1547/1547 - 1s - 682us/step - loss: 0.0113 - val_loss: 0.0077\n",
      "Epoch 31/40\n",
      "1547/1547 - 1s - 680us/step - loss: 0.0112 - val_loss: 0.0084\n",
      "Epoch 32/40\n",
      "1547/1547 - 1s - 679us/step - loss: 0.0112 - val_loss: 0.0078\n",
      "Epoch 33/40\n",
      "1547/1547 - 1s - 711us/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 34/40\n",
      "1547/1547 - 1s - 678us/step - loss: 0.0110 - val_loss: 0.0078\n",
      "Epoch 35/40\n",
      "1547/1547 - 1s - 677us/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 36/40\n",
      "1547/1547 - 1s - 677us/step - loss: 0.0107 - val_loss: 0.0075\n",
      "Epoch 37/40\n",
      "1547/1547 - 1s - 677us/step - loss: 0.0108 - val_loss: 0.0071\n",
      "Epoch 38/40\n",
      "1547/1547 - 1s - 679us/step - loss: 0.0106 - val_loss: 0.0079\n",
      "Epoch 39/40\n",
      "1547/1547 - 1s - 711us/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 40/40\n",
      "1547/1547 - 1s - 681us/step - loss: 0.0102 - val_loss: 0.0075\n"
     ]
    }
   ],
   "source": [
    "# fit the autoencoder model to reconstruct input\n",
    "history = model.fit(x_train, x_train, epochs=40, batch_size=32, verbose=2, validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219us/step\n"
     ]
    }
   ],
   "source": [
    "# define an encoder model (without the decoder)\n",
    "encoder = Model(inputs=visible, outputs=bottleneck)\n",
    "\n",
    "# # save the encoder to file\n",
    "# encoder.save('encoder.keras')\n",
    "# encoder = load_model('encoder.keras')\n",
    "\n",
    "# encode the train data\n",
    "x_train_encode = encoder.predict(x_train)\n",
    "\n",
    "# encode the test data\n",
    "x_test_encode = encoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7104866088268578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# define AE_model\n",
    "AE_model = LogisticRegression()\n",
    "\n",
    "# fit AE_model on training set\n",
    "AE_model.fit(x_train_encode, y_train)\n",
    "\n",
    "# make prediction on test set\n",
    "yhat = AE_model.predict(x_test_encode)\n",
    "\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from keras.layers import Activation\n",
    "\n",
    "\n",
    "# creating neural net\n",
    "nn_model = Sequential()\n",
    "nn_model.add(Input(shape=(7,)))\n",
    "nn_model.add(Dense(14, activation = 'relu'))\n",
    "nn_model.add(Dense(5, activation = 'relu'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01, beta_1=0.9)\n",
    "\n",
    "nn_model.compile(optimizer=optimizer,\n",
    "              loss='BinaryCrossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_294 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_295 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_296 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_294 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_295 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m75\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_296 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> (772.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193\u001b[0m (772.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - accuracy: 0.6963 - loss: 0.5918\n",
      "Epoch 2/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7098 - loss: 0.5737\n",
      "Epoch 3/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7068 - loss: 0.5721\n",
      "Epoch 4/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step - accuracy: 0.7083 - loss: 0.5715\n",
      "Epoch 5/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7053 - loss: 0.5732\n",
      "Epoch 6/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7091 - loss: 0.5703\n",
      "Epoch 7/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step - accuracy: 0.7117 - loss: 0.5652\n",
      "Epoch 8/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step - accuracy: 0.7121 - loss: 0.5666\n",
      "Epoch 9/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - accuracy: 0.7089 - loss: 0.5688\n",
      "Epoch 10/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - accuracy: 0.7109 - loss: 0.5670\n",
      "Epoch 11/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - accuracy: 0.7105 - loss: 0.5656\n",
      "Epoch 12/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - accuracy: 0.7153 - loss: 0.5639\n",
      "Epoch 13/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - accuracy: 0.7106 - loss: 0.5656\n",
      "Epoch 14/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7136 - loss: 0.5620\n",
      "Epoch 15/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - accuracy: 0.7113 - loss: 0.5630\n",
      "Epoch 16/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - accuracy: 0.7136 - loss: 0.5612\n",
      "Epoch 17/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step - accuracy: 0.7117 - loss: 0.5654\n",
      "Epoch 18/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - accuracy: 0.7130 - loss: 0.5641\n",
      "Epoch 19/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7121 - loss: 0.5622\n",
      "Epoch 20/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7112 - loss: 0.5612\n",
      "Epoch 21/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265us/step - accuracy: 0.7140 - loss: 0.5597\n",
      "Epoch 22/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - accuracy: 0.7146 - loss: 0.5600\n",
      "Epoch 23/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - accuracy: 0.7145 - loss: 0.5595\n",
      "Epoch 24/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7167 - loss: 0.5571\n",
      "Epoch 25/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - accuracy: 0.7113 - loss: 0.5607\n",
      "Epoch 26/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7145 - loss: 0.5606\n",
      "Epoch 27/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 266us/step - accuracy: 0.7170 - loss: 0.5563\n",
      "Epoch 28/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - accuracy: 0.7139 - loss: 0.5583\n",
      "Epoch 29/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - accuracy: 0.7148 - loss: 0.5587\n",
      "Epoch 30/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274us/step - accuracy: 0.7106 - loss: 0.5618\n",
      "Epoch 31/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7143 - loss: 0.5601\n",
      "Epoch 32/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7112 - loss: 0.5592\n",
      "Epoch 33/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272us/step - accuracy: 0.7151 - loss: 0.5592\n",
      "Epoch 34/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7096 - loss: 0.5623\n",
      "Epoch 35/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step - accuracy: 0.7101 - loss: 0.5610\n",
      "Epoch 36/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270us/step - accuracy: 0.7172 - loss: 0.5547\n",
      "Epoch 37/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 269us/step - accuracy: 0.7136 - loss: 0.5586\n",
      "Epoch 38/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271us/step - accuracy: 0.7136 - loss: 0.5585\n",
      "Epoch 39/50\n",
      "\u001b[1m3093/3093\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273us/step - accuracy: 0.7133 - loss: 0.5586\n",
      "Epoch 40/50\n",
      "\u001b[1m 358/3093\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 281us/step - accuracy: 0.7254 - loss: 0.5553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[362], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# fit the model to the training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_encode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bigdata/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "nn_model.fit(x_train_encode, y_train, epochs=50, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test dataset\n",
    "score = nn_model.evaluate(x_test_encode, y_test, batch_size=100)\n",
    "print(score[0])\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_145\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_145\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_239 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">924</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_173         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_173 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_240 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_174         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_174 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_241 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">220</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_175         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_175 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_242 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_254 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_255 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_256 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_29 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_239 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │           \u001b[38;5;34m924\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_173         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │           \u001b[38;5;34m168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_173 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_240 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │           \u001b[38;5;34m903\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_174         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │            \u001b[38;5;34m84\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_174 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_241 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m220\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_175         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_175 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_242 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m77\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_254 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_255 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_256 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,557</span> (9.99 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,557\u001b[0m (9.99 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">141</span> (564.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m141\u001b[0m (564.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> (9.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,416\u001b[0m (9.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# add new classifier layers\n",
    "\n",
    "class1 = Dense(10, activation='relu')(encoder.layers[-1].output)\n",
    "class2 = Dense(5, activation='relu')(class1)\n",
    "output = Dense(1, activation='sigmoid')(class2)\n",
    "\n",
    "nn_encoder = Model(inputs=encoder.inputs, outputs=output)\n",
    "\n",
    "print(nn_encoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 478us/step - accuracy: 0.6966 - loss: 0.5780 - val_accuracy: 0.7153 - val_loss: 0.5601\n",
      "Epoch 2/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7118 - loss: 0.5635 - val_accuracy: 0.7170 - val_loss: 0.5574\n",
      "Epoch 3/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.7138 - loss: 0.5602 - val_accuracy: 0.7184 - val_loss: 0.5547\n",
      "Epoch 4/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7154 - loss: 0.5557 - val_accuracy: 0.7193 - val_loss: 0.5530\n",
      "Epoch 5/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.7124 - loss: 0.5576 - val_accuracy: 0.7194 - val_loss: 0.5519\n",
      "Epoch 6/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 422us/step - accuracy: 0.7177 - loss: 0.5544 - val_accuracy: 0.7187 - val_loss: 0.5520\n",
      "Epoch 7/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - accuracy: 0.7167 - loss: 0.5546 - val_accuracy: 0.7176 - val_loss: 0.5521\n",
      "Epoch 8/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 421us/step - accuracy: 0.7151 - loss: 0.5556 - val_accuracy: 0.7169 - val_loss: 0.5537\n",
      "Epoch 9/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 427us/step - accuracy: 0.7108 - loss: 0.5593 - val_accuracy: 0.7193 - val_loss: 0.5503\n",
      "Epoch 10/10\n",
      "\u001b[1m1547/1547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 456us/step - accuracy: 0.7168 - loss: 0.5518 - val_accuracy: 0.7205 - val_loss: 0.5506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2d7de30b0>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "for layer in nn_encoder.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001, beta_1=0.9)\n",
    "# optimizer = \"Adam\"\n",
    "nn_encoder.compile(optimizer=optimizer, loss=\"BinaryCrossentropy\", metrics=['accuracy'])\n",
    "\n",
    "nn_encoder.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239us/step - accuracy: 0.7194 - loss: 0.5486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5506343841552734, 0.7205299735069275]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn_encoder.predict(x_test)\n",
    "nn_encoder.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, our definition of be abling to \"make out\" the phrase \"Lee\" was that we'd have to be able to recognize \"Lee\" without referencing the original image. Hence, we found that we had to go up to around 200 latent dimensions before we could get something that is legible enough to more clearly be \"Lee\". However, we found that the plaid/checkered pattern became more clearly recognizable around 100 latent dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.4**: Run the experiment using different values of `latent_dim` (e.g. `[2,16,64,128,512]`) and store the validation loss of the last iteration in the `history` variable for each. Then plot it, my plot looks [like this](https://dhsvendsen.github.io/images/latentdim_vs_reconerror.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dims = [2,16,64,128,512]\n",
    "val_losses = []\n",
    "\n",
    "for dim in latent_dims:\n",
    "    print(\"\\nExperiment \" + str(len(val_losses) + 1) + \":\")\n",
    "    autoencoder_vl = Autoencoder(latent_dim = dim)\n",
    "    autoencoder_vl.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "    history_vl = autoencoder_vl.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "    val_losses.append(history_vl.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(latent_dim, val_losses, marker='o')\n",
    "plt.title('Validation Loss vs. Latent Dimension')\n",
    "plt.xlabel('Latent Dimension')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.5**: Set the `latent_dim = 2` and describe what happens to the test data - what do you think happens to the sandal? Then plot the representation of the test data in the latent space, colouring each point according to its class and describe what you see. [Example plot](https://dhsvendsen.github.io/images/two_latent_dims_simple.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(encoded_imgs[:,0],encoded_imgs[:,1],color=[\"C\"+str(i) for i in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When latent_dim = 2, the sandal reconstruction becomes indifferenitable from the sneaker reconstruction. Their reconstructions are nearly identical. The plaid shirt also begins to resemble an outline of a pair of sneaker and pants.\n",
    "\n",
    "We believe this is because, when we limit our dimensions to only 2 dimensions, the autoencoder must extract general traits that are broadly shared among the clothing categories. For example, it extracts a general feature shared by different types of footwear and another feature shared by pants and jackets. There could also be some class bias where, for example, there are more sneakers than flip-flops so that a flip-flop is more likely to be reconstructed as a sneaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 7.1.6**: It appears that the encoding and decoding scheme is not very effective! Add an extra `Dense` layer of `128` neurons (or more) with `activation='relu'` to both the encoder and the decoder; plot the reconstructions of the test images again. We are cramming all the information of 784 pixels into a 2-dimensional vector space - lets see if there is a way to do it which retains key information. Plot the 2-D latent representation of the test data again. Using this ([Example](https://dhsvendsen.github.io/images/two_latent_dims_ordered.png)) plot, explain why our reconstruction error is lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder128(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder128, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(latent_dim, activation='relu')\n",
    "            ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(784, activation='sigmoid'),\n",
    "            layers.Reshape((28, 28))\n",
    "            ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder128 = Autoencoder128(latent_dim = 2)\n",
    "autoencoder128.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "history = autoencoder128.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization cell\n",
    "encoded_imgs = autoencoder128.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder128.decoder(encoded_imgs).numpy()\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(encoded_imgs[:,0],encoded_imgs[:,1],color=[\"C\"+str(i) for i in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reconstruction error is lower because it enhances both encoding and decoding.\n",
    "\n",
    "`Encoding` improves because the added layer is another feature extractor that is able to extract higher-level features before compression. These provide more information (e.g. flip-flop straps, sole shape, etc.) that can be better condensed into more informative macro features. Moreover, features that are shared between separate classes are viewed in greater context as higher-level features so that the model can more easily condense them in a manner where these shared features are more distinguishable by classes. For example, pants and jackets both have sleeves, but adding another layer can give more information about the positioning of sleeves that differentiate jackets and pants. This can then be compressed into a latent space with more informative dimensions.  \n",
    "\n",
    "`Decoding`improves because there is another layer with more neurons that can extract some lower-level features from the compression before being passed onto a larger Dense layer that can go further and parcel out higher-level features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
